{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.classify.maxent import MaxentClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('Data/Data_dat_dai/data_after_preprocessing.csv', index_col=0)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train, df_test = train_test_split(df,test_size=0.15,random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('Data/Data_dat_dai/df_train_after.csv')\n",
    "df_test = pd.read_csv('Data/Data_dat_dai/df_test_after.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_label_train = df_train['label'].to_list()\n",
    "list_text_train = df_train['text'].to_list()\n",
    "list_train = []\n",
    "for i in range(len(list_text_train)):\n",
    "    list_train.append((list_text_train[i].split(' '),list_label_train[i]))\n",
    "\n",
    "list_label_test = df_test['label'].to_list()\n",
    "list_text_test = df_test['text'].to_list()\n",
    "list_test = []\n",
    "for i in range(len(list_label_test)):\n",
    "    list_test.append((list_text_test[i].split(' '),list_label_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_dict(words_list):\n",
    "  return dict([(word, True) for word in words_list])\n",
    " \n",
    "training_set_formatted = [(list_to_dict(element[0]), element[1]) for element in list_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_formatted = [(list_to_dict(element[0]), element[1]) for element in list_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (300 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.596\n",
      "             2          -0.69047        0.786\n",
      "             3          -0.68782        0.789\n",
      "             4          -0.68520        0.791\n",
      "             5          -0.68260        0.791\n",
      "             6          -0.68003        0.794\n",
      "             7          -0.67749        0.799\n",
      "             8          -0.67497        0.802\n",
      "             9          -0.67247        0.803\n",
      "            10          -0.67000        0.805\n",
      "            11          -0.66755        0.808\n",
      "            12          -0.66513        0.808\n",
      "            13          -0.66273        0.808\n",
      "            14          -0.66035        0.811\n",
      "            15          -0.65800        0.814\n",
      "            16          -0.65566        0.816\n",
      "            17          -0.65335        0.819\n",
      "            18          -0.65107        0.821\n",
      "            19          -0.64880        0.825\n",
      "            20          -0.64655        0.828\n",
      "            21          -0.64433        0.830\n",
      "            22          -0.64213        0.832\n",
      "            23          -0.63994        0.832\n",
      "            24          -0.63778        0.833\n",
      "            25          -0.63563        0.836\n",
      "            26          -0.63351        0.836\n",
      "            27          -0.63140        0.838\n",
      "            28          -0.62932        0.839\n",
      "            29          -0.62725        0.841\n",
      "            30          -0.62520        0.841\n",
      "            31          -0.62317        0.842\n",
      "            32          -0.62115        0.842\n",
      "            33          -0.61915        0.844\n",
      "            34          -0.61717        0.844\n",
      "            35          -0.61521        0.846\n",
      "            36          -0.61326        0.847\n",
      "            37          -0.61133        0.847\n",
      "            38          -0.60942        0.847\n",
      "            39          -0.60752        0.846\n",
      "            40          -0.60564        0.847\n",
      "            41          -0.60377        0.849\n",
      "            42          -0.60192        0.849\n",
      "            43          -0.60008        0.850\n",
      "            44          -0.59826        0.852\n",
      "            45          -0.59645        0.853\n",
      "            46          -0.59466        0.853\n",
      "            47          -0.59288        0.852\n",
      "            48          -0.59112        0.852\n",
      "            49          -0.58937        0.852\n",
      "            50          -0.58763        0.853\n",
      "            51          -0.58591        0.855\n",
      "            52          -0.58420        0.855\n",
      "            53          -0.58250        0.856\n",
      "            54          -0.58081        0.856\n",
      "            55          -0.57914        0.856\n",
      "            56          -0.57748        0.856\n",
      "            57          -0.57584        0.856\n",
      "            58          -0.57420        0.858\n",
      "            59          -0.57258        0.858\n",
      "            60          -0.57097        0.858\n",
      "            61          -0.56937        0.860\n",
      "            62          -0.56778        0.861\n",
      "            63          -0.56621        0.864\n",
      "            64          -0.56464        0.864\n",
      "            65          -0.56309        0.864\n",
      "            66          -0.56155        0.867\n",
      "            67          -0.56002        0.867\n",
      "            68          -0.55850        0.867\n",
      "            69          -0.55699        0.867\n",
      "            70          -0.55549        0.867\n",
      "            71          -0.55400        0.867\n",
      "            72          -0.55252        0.867\n",
      "            73          -0.55105        0.869\n",
      "            74          -0.54960        0.869\n",
      "            75          -0.54815        0.869\n",
      "            76          -0.54671        0.869\n",
      "            77          -0.54528        0.869\n",
      "            78          -0.54386        0.869\n",
      "            79          -0.54246        0.871\n",
      "            80          -0.54106        0.871\n",
      "            81          -0.53967        0.871\n",
      "            82          -0.53828        0.871\n",
      "            83          -0.53691        0.871\n",
      "            84          -0.53555        0.871\n",
      "            85          -0.53420        0.869\n",
      "            86          -0.53285        0.869\n",
      "            87          -0.53151        0.869\n",
      "            88          -0.53019        0.869\n",
      "            89          -0.52887        0.872\n",
      "            90          -0.52756        0.874\n",
      "            91          -0.52625        0.874\n",
      "            92          -0.52496        0.874\n",
      "            93          -0.52367        0.875\n",
      "            94          -0.52240        0.875\n",
      "            95          -0.52113        0.875\n",
      "            96          -0.51987        0.880\n",
      "            97          -0.51861        0.880\n",
      "            98          -0.51737        0.880\n",
      "            99          -0.51613        0.880\n",
      "           100          -0.51490        0.880\n",
      "           101          -0.51367        0.880\n",
      "           102          -0.51246        0.883\n",
      "           103          -0.51125        0.885\n",
      "           104          -0.51005        0.886\n",
      "           105          -0.50885        0.888\n",
      "           106          -0.50767        0.888\n",
      "           107          -0.50649        0.888\n",
      "           108          -0.50532        0.888\n",
      "           109          -0.50415        0.888\n",
      "           110          -0.50299        0.889\n",
      "           111          -0.50184        0.889\n",
      "           112          -0.50070        0.891\n",
      "           113          -0.49956        0.891\n",
      "           114          -0.49843        0.891\n",
      "           115          -0.49730        0.891\n",
      "           116          -0.49618        0.891\n",
      "           117          -0.49507        0.891\n",
      "           118          -0.49397        0.891\n",
      "           119          -0.49287        0.891\n",
      "           120          -0.49177        0.892\n",
      "           121          -0.49069        0.894\n",
      "           122          -0.48961        0.894\n",
      "           123          -0.48853        0.894\n",
      "           124          -0.48747        0.895\n",
      "           125          -0.48640        0.894\n",
      "           126          -0.48535        0.895\n",
      "           127          -0.48430        0.895\n",
      "           128          -0.48325        0.895\n",
      "           129          -0.48221        0.895\n",
      "           130          -0.48118        0.895\n",
      "           131          -0.48015        0.895\n",
      "           132          -0.47913        0.895\n",
      "           133          -0.47812        0.895\n",
      "           134          -0.47711        0.895\n",
      "           135          -0.47610        0.895\n",
      "           136          -0.47510        0.895\n",
      "           137          -0.47411        0.895\n",
      "           138          -0.47312        0.895\n",
      "           139          -0.47214        0.897\n",
      "           140          -0.47116        0.897\n",
      "           141          -0.47018        0.897\n",
      "           142          -0.46922        0.897\n",
      "           143          -0.46825        0.897\n",
      "           144          -0.46730        0.897\n",
      "           145          -0.46634        0.897\n",
      "           146          -0.46540        0.899\n",
      "           147          -0.46445        0.899\n",
      "           148          -0.46352        0.899\n",
      "           149          -0.46258        0.899\n",
      "           150          -0.46166        0.899\n",
      "           151          -0.46073        0.899\n",
      "           152          -0.45981        0.899\n",
      "           153          -0.45890        0.899\n",
      "           154          -0.45799        0.899\n",
      "           155          -0.45709        0.899\n",
      "           156          -0.45619        0.899\n",
      "           157          -0.45529        0.899\n",
      "           158          -0.45440        0.899\n",
      "           159          -0.45352        0.899\n",
      "           160          -0.45263        0.900\n",
      "           161          -0.45176        0.900\n",
      "           162          -0.45088        0.903\n",
      "           163          -0.45001        0.903\n",
      "           164          -0.44915        0.905\n",
      "           165          -0.44829        0.906\n",
      "           166          -0.44743        0.906\n",
      "           167          -0.44658        0.906\n",
      "           168          -0.44574        0.906\n",
      "           169          -0.44489        0.906\n",
      "           170          -0.44405        0.906\n",
      "           171          -0.44322        0.906\n",
      "           172          -0.44239        0.908\n",
      "           173          -0.44156        0.908\n",
      "           174          -0.44074        0.910\n",
      "           175          -0.43992        0.910\n",
      "           176          -0.43910        0.910\n",
      "           177          -0.43829        0.910\n",
      "           178          -0.43748        0.911\n",
      "           179          -0.43668        0.911\n",
      "           180          -0.43588        0.911\n",
      "           181          -0.43508        0.911\n",
      "           182          -0.43429        0.911\n",
      "           183          -0.43350        0.911\n",
      "           184          -0.43272        0.911\n",
      "           185          -0.43194        0.911\n",
      "           186          -0.43116        0.911\n",
      "           187          -0.43039        0.911\n",
      "           188          -0.42962        0.911\n",
      "           189          -0.42885        0.911\n",
      "           190          -0.42808        0.911\n",
      "           191          -0.42733        0.911\n",
      "           192          -0.42657        0.911\n",
      "           193          -0.42582        0.911\n",
      "           194          -0.42507        0.911\n",
      "           195          -0.42432        0.911\n",
      "           196          -0.42358        0.911\n",
      "           197          -0.42284        0.911\n",
      "           198          -0.42210        0.911\n",
      "           199          -0.42137        0.911\n",
      "           200          -0.42064        0.911\n",
      "           201          -0.41991        0.911\n",
      "           202          -0.41919        0.911\n",
      "           203          -0.41847        0.911\n",
      "           204          -0.41775        0.911\n",
      "           205          -0.41704        0.911\n",
      "           206          -0.41633        0.911\n",
      "           207          -0.41562        0.911\n",
      "           208          -0.41492        0.911\n",
      "           209          -0.41422        0.911\n",
      "           210          -0.41352        0.911\n",
      "           211          -0.41282        0.911\n",
      "           212          -0.41213        0.911\n",
      "           213          -0.41144        0.911\n",
      "           214          -0.41075        0.913\n",
      "           215          -0.41007        0.913\n",
      "           216          -0.40939        0.913\n",
      "           217          -0.40871        0.913\n",
      "           218          -0.40804        0.913\n",
      "           219          -0.40737        0.914\n",
      "           220          -0.40670        0.914\n",
      "           221          -0.40603        0.914\n",
      "           222          -0.40537        0.914\n",
      "           223          -0.40471        0.914\n",
      "           224          -0.40405        0.914\n",
      "           225          -0.40339        0.914\n",
      "           226          -0.40274        0.914\n",
      "           227          -0.40209        0.914\n",
      "           228          -0.40145        0.914\n",
      "           229          -0.40080        0.914\n",
      "           230          -0.40016        0.914\n",
      "           231          -0.39952        0.914\n",
      "           232          -0.39888        0.914\n",
      "           233          -0.39825        0.914\n",
      "           234          -0.39762        0.914\n",
      "           235          -0.39699        0.914\n",
      "           236          -0.39636        0.914\n",
      "           237          -0.39574        0.914\n",
      "           238          -0.39512        0.914\n",
      "           239          -0.39450        0.914\n",
      "           240          -0.39388        0.916\n",
      "           241          -0.39327        0.916\n",
      "           242          -0.39266        0.916\n",
      "           243          -0.39205        0.916\n",
      "           244          -0.39144        0.916\n",
      "           245          -0.39084        0.917\n",
      "           246          -0.39024        0.917\n",
      "           247          -0.38964        0.917\n",
      "           248          -0.38904        0.917\n",
      "           249          -0.38845        0.917\n",
      "           250          -0.38786        0.917\n",
      "           251          -0.38727        0.917\n",
      "           252          -0.38668        0.917\n",
      "           253          -0.38609        0.917\n",
      "           254          -0.38551        0.917\n",
      "           255          -0.38493        0.917\n",
      "           256          -0.38435        0.917\n",
      "           257          -0.38377        0.917\n",
      "           258          -0.38320        0.917\n",
      "           259          -0.38263        0.917\n",
      "           260          -0.38206        0.919\n",
      "           261          -0.38149        0.919\n",
      "           262          -0.38092        0.919\n",
      "           263          -0.38036        0.919\n",
      "           264          -0.37980        0.919\n",
      "           265          -0.37924        0.919\n",
      "           266          -0.37868        0.920\n",
      "           267          -0.37813        0.920\n",
      "           268          -0.37757        0.920\n",
      "           269          -0.37702        0.920\n",
      "           270          -0.37648        0.920\n",
      "           271          -0.37593        0.920\n",
      "           272          -0.37538        0.920\n",
      "           273          -0.37484        0.922\n",
      "           274          -0.37430        0.922\n",
      "           275          -0.37376        0.922\n",
      "           276          -0.37322        0.922\n",
      "           277          -0.37269        0.922\n",
      "           278          -0.37216        0.922\n",
      "           279          -0.37163        0.922\n",
      "           280          -0.37110        0.922\n",
      "           281          -0.37057        0.922\n",
      "           282          -0.37004        0.922\n",
      "           283          -0.36952        0.922\n",
      "           284          -0.36900        0.922\n",
      "           285          -0.36848        0.924\n",
      "           286          -0.36796        0.924\n",
      "           287          -0.36745        0.924\n",
      "           288          -0.36693        0.924\n",
      "           289          -0.36642        0.924\n",
      "           290          -0.36591        0.924\n",
      "           291          -0.36540        0.924\n",
      "           292          -0.36489        0.925\n",
      "           293          -0.36439        0.925\n",
      "           294          -0.36389        0.925\n",
      "           295          -0.36338        0.925\n",
      "           296          -0.36288        0.925\n",
      "           297          -0.36239        0.925\n",
      "           298          -0.36189        0.925\n",
      "           299          -0.36139        0.925\n",
      "         Final          -0.36090        0.925\n",
      "  -0.074 tầng==True and label is 1\n",
      "  -0.072 vương_đình==True and label is -1\n",
      "  -0.068 mấy==True and label is 1\n",
      "  -0.066 xu_thế==True and label is -1\n",
      "  -0.065 internet==True and label is -1\n",
      "  -0.065 nhà_cửa==True and label is 1\n",
      "   0.065 xã_hội_chủ_nghĩa_là==True and label is -1\n",
      "  -0.064 nuôi_trồng==True and label is -1\n",
      "  -0.063 2006==True and label is 1\n",
      "  -0.063 loại_bỏ==True and label is -1\n"
     ]
    }
   ],
   "source": [
    "algorithm = nltk.classify.MaxentClassifier.ALGORITHMS[0]\n",
    "mx = MaxentClassifier.train(training_set_formatted, algorithm,max_iter = 300)\n",
    "mx.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = mx.classify_many([test_set_formatted[i][0] for i in range(len(list_label_test))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maxent Accuracy Score ->  84.21052631578947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.89      0.70      0.78        46\n",
      "           1       0.82      0.94      0.88        68\n",
      "\n",
      "    accuracy                           0.84       114\n",
      "   macro avg       0.85      0.82      0.83       114\n",
      "weighted avg       0.85      0.84      0.84       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Maxent Accuracy Score -> \",accuracy_score(list_label_test, y_test_pred)*100)\n",
    "print(classification_report(list_label_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
